{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy.io import loadmat\n",
    "import spectral as spy\n",
    "import numpy as np\n",
    "import hypers as hp\n",
    "import openpyxl\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pylab as pl\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA as sk_pca\n",
    "#from sklearn.decomposition import LDA\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import savgol_filter\n",
    "import pylab as pl\n",
    "from spectral import *\n",
    "import spectral.io.envi as envi\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_score , KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import time  \n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import find_peaks_cwt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import keras as K\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(K.layers.Conv1D(32, 8,strides=8, padding='same',input_shape=(1001,1), activation='relu'))\n",
    "model.add(K.layers.Conv1D(32, 5,strides=5, padding='same', activation='relu'))\n",
    "model.add(K.layers.Conv1D(32, 3,strides=3, padding='same', activation='relu'))\n",
    "model.add(K.layers.pooling.GlobalAveragePooling1D())\n",
    "model.add(K.layers.Dense(26, activation='softmax'))\n",
    "        \n",
    "        #Define optimizer        \n",
    "optimizer =keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "        \n",
    "        # Compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['categorical_accuracy'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=pd.read_csv(\"D:/地理毕业论文/nois8,19healthyspec18.csv\")\n",
    "for i in range(800):\n",
    "    if i >4:\n",
    "        DF = DF.drop(DF[DF.iloc[:,i]<0].index)\n",
    "DF=DF.reset_index(drop=True)\n",
    "spectral=DF.iloc[:,6:1007]\n",
    "name=DF[\"ScientifName\"]\n",
    "df=pd.concat([name,spectral],axis=1)\n",
    "class_mapping = {label:idx for idx,label in enumerate(set(df['ScientifName']))}\n",
    "df['ScientifName_num'] = df['ScientifName'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skpca1 = sk_pca(n_components=10)\n",
    "nfeat1 = StandardScaler().fit_transform(spectral.values)\n",
    "dfeat = savgol_filter(spectral.values, 1000, polyorder = 25, deriv=1)\n",
    "nfeat2 = StandardScaler().fit_transform(dfeat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=[]\n",
    "for name, hex in matplotlib.colors.cnames.items():\n",
    "  if len(color)<=26:\n",
    "    if hex not in color:\n",
    "      color.append(hex)\n",
    "unique=list(set(df['ScientifName_num']))\n",
    "colu=list()\n",
    "for i in unique:\n",
    "    a=color[0]\n",
    "    df['ScientifName_num']=df['ScientifName_num'].replace(i,a)\n",
    "    color.remove(a)\n",
    "dict={}\n",
    "for i in range(len(df['ScientifName'])):\n",
    "    dict[df['ScientifName'][i]]=df['ScientifName_num'][i]\n",
    "dict['Diplonychus Condylocarpon']='#FFB6C1'\n",
    "dict['Combretum Albopunctatum']='#DC143C'\n",
    "dict['Scherocarya Birrea']=\"#4B0082\"\n",
    "dict['Baikiaea Plurjuga']=\"#7B68EE\"\n",
    "dict['Acacia Senegal']=\"#191970\"\n",
    "dict['Acacia Hebeclada']=\"#708090\"\n",
    "dict['Berchemia Discolor']=\"#00BFFF\"\n",
    "dict['Combretum Elaeagnoides']=\"#00FA9A\"\n",
    "dict['Combretum Zeyheri']=\"#98FB98\"\n",
    "dict['Adansonia Digitata']=\"#008000\"\n",
    "dict['Ochna Pulchura']=\"#F5F5DC\"\n",
    "dict['Pretocarpus Rotundifolius']=\"#BDB76B\"\n",
    "\n",
    "dict['Croton Gratissimus']=\"#DAA520\"\n",
    "dict['Combretum Apiculatum']=\"#A0522D\"\n",
    "dict['Acacia_Nigrescens']=\"#F08080\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skpca1 = sk_pca(n_components=10)\n",
    "skpca2 = sk_pca(n_components=10)\n",
    "# Read the features (scans) and transform data from reflectance to absorbance\n",
    "\n",
    "# Calculate first derivative applying a Savitzky-Golay filter\n",
    "dfeat = savgol_filter(spectral.values, 1000, polyorder = 25, deriv=1) \n",
    "# Scale the features to have zero mean and standard devisation of 1\n",
    "# This is important when correlating data with very different variances\n",
    "nfeat1 = StandardScaler().fit_transform(spectral.values)\n",
    "nfeat2 = StandardScaler().fit_transform(dfeat)\n",
    " \n",
    "# Fit the spectral data and extract the explained variance ratio\n",
    "X1 = skpca1.fit(nfeat1)\n",
    "expl_var_1 = X1.explained_variance_ratio_\n",
    " \n",
    "# Fit the first data and extract the explained variance ratio\n",
    "X2 = skpca2.fit(nfeat2)\n",
    "expl_var_2 = X2.explained_variance_ratio_\n",
    " \n",
    "# Plot data\n",
    "with plt.style.context(('ggplot')):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(9,6))\n",
    "    fig.set_tight_layout(True)\n",
    " \n",
    "    ax1.plot(expl_var_1,'-o', label=\"Explained Variance %\")\n",
    "    ax1.plot(np.cumsum(expl_var_1),'-o', label = 'Cumulative variance %')\n",
    "    ax1.set_xlabel(\"PC number\")\n",
    "    ax1.set_title('Absorbance data')\n",
    " \n",
    "    ax2.plot(expl_var_2,'-o', label=\"Explained Variance %\")\n",
    "    ax2.plot(np.cumsum(expl_var_2),'-o', label = 'Cumulative variance %')\n",
    "    ax2.set_xlabel(\"PC number\")\n",
    "    ax2.set_title('First derivative data')\n",
    " \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['ScientifName']\n",
    "x=nfeat1\n",
    "lda = LDA(n_components=9)\n",
    "Xlda = lda.fit_transform(x,y)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2)\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lda.predict(X_test)\n",
    "print(lda.score(X_test,y_test))\n",
    "fig = px.scatter(x=Xlda[:,0], y=Xlda[:,1], color=df['ScientifName'],color_discrete_map=dict,width=1000, height=500)\n",
    "#fig.show()\n",
    "fig = px.scatter(x=Xlda[:,1], y=Xlda[:,2], color=df['ScientifName'],color_discrete_map=dict,width=1000, height=500)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['ScientifName']\n",
    "x=nfeat1\n",
    "lda = LDA(n_components=9)\n",
    "Xlda = lda.fit_transform(x,y)\n",
    "Xlda\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2)\n",
    "\n",
    "lda = LDA(n_components=9)\n",
    "lda.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lda.predict(X_test)\n",
    "print(lda.score(X_test,y_test))\n",
    "fig = px.scatter(x=Xlda[:,0], y=Xlda[:,1], color=df['ScientifName'],hover_name=df['ScientifName'],color_discrete_map=dict,width=1000, height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/ldanewScientifName1.html\")\n",
    "fig = px.scatter(x=Xlda[:,1], y=Xlda[:,2], color=df['ScientifName'],hover_name=df['ScientifName'],color_discrete_map=dict,width=1000, height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/ldanewScientifName2.html\")\n",
    "fig = px.scatter(x=Xlda[:,2], y=Xlda[:,3], color=df['ScientifName'],hover_name=df['ScientifName'],color_discrete_map=dict,width=1000, height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/ldanewScientifName3.html\")\n",
    "fig = px.scatter(x=Xlda[:,3], y=Xlda[:,4], color=df['ScientifName'],hover_name=df['ScientifName'],color_discrete_map=dict,width=1000, height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/ldanewScientifName4.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=DF['ScientifName']\n",
    "x=nfeat1\n",
    "skpca2 = sk_pca(n_components=10) \n",
    "# Transform on the scaled features\n",
    "Xt = skpca2.fit_transform(nfeat1)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "fig = px.scatter(x=Xt[:,0], y=Xt[:,1], color=DF['ScientifName'],color_discrete_map=dict,hover_name=DF['ScientifName'], width=1000,height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaScientifName1.html\")\n",
    "fig = px.scatter(x=Xt[:,1], y=Xt[:,2], color=DF['ScientifName'],color_discrete_map=dict,hover_name=DF['ScientifName'],width=1000, height=800)\n",
    "#fig.show()\n",
    "\n",
    "fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaScientifName2.html\")\n",
    "fig = px.scatter(x=Xt[:,2], y=Xt[:,3], color=DF['ScientifName'],color_discrete_map=dict,hover_name=DF['ScientifName'],width=1000, height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaScientifName3.html\")\n",
    "fig = px.scatter(x=Xt[:,3], y=Xt[:,4], color=DF['ScientifName'],color_discrete_map=dict,hover_name=DF['ScientifName'],width=1000, height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaScientifName4.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=DF['fire or drought Sensitivity']\n",
    "x=nfeat1\n",
    "skpca2 = sk_pca(n_components=10) \n",
    "# Transform on the scaled features\n",
    "Xt = skpca2.fit_transform(nfeat1)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "fig = px.scatter(x=Xt[:,0], y=Xt[:,1], color=DF['fire or drought Sensitivity'],hover_name=DF['ScientifName'], width=1000,height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaDroughtfireSensitivity1.html\")\n",
    "fig = px.scatter(x=Xt[:,1], y=Xt[:,2], color=DF['fire or drought Sensitivity'],hover_name=DF['ScientifName'],width=1000, height=500)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaDroughtfireSensitivity2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=DF['fire or drought Sensitivity']\n",
    "x=spectral\n",
    "skpca2 = sk_pca(n_components=10) \n",
    "# Transform on the scaled features\n",
    "Xt = skpca2.fit_transform(nfeat1)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "fig = px.scatter(x=Xt[:,0], y=Xt[:,1], color=DF['fire or drought Sensitivity'],hover_name=DF['ScientifName'], width=1000,height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaDroughtfireSensitivity1.html\")\n",
    "fig = px.scatter(x=Xt[:,1], y=Xt[:,2], color=DF['fire or drought Sensitivity'],hover_name=DF['ScientifName'], width=1000,height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaDroughtfireSensitivity1.html\")\n",
    "fig = px.scatter(x=Xt[:,2], y=Xt[:,3], color=DF['fire or drought Sensitivity'],hover_name=DF['ScientifName'], width=1000,height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaDroughtfireSensitivity1.html\")\n",
    "\n",
    "fig = px.scatter(x=Xt[:,3], y=Xt[:,4], color=DF['fire or drought Sensitivity'],hover_name=DF['ScientifName'],width=1000, height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaDroughtfireSensitivity2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=DF['DroughtSensitivity']\n",
    "x=spectral\n",
    "skpca2 = sk_pca(n_components=10) \n",
    "# Transform on the scaled features\n",
    "Xt = skpca2.fit_transform(nfeat1)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "fig = px.scatter(x=Xt[:,0], y=Xt[:,1], color=DF['DroughtSensitivity'],hover_name=DF['ScientifName'], width=1000,height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaDroughtSensitivity1.html\")\n",
    "fig = px.scatter(x=Xt[:,1], y=Xt[:,2], color=DF['DroughtSensitivity'],hover_name=DF['ScientifName'], width=1000,height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaDroughtSensitivity2.html\")\n",
    "fig = px.scatter(x=Xt[:,2], y=Xt[:,3], color=DF['DroughtSensitivity'],hover_name=DF['ScientifName'], width=1000,height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaDroughtSensitivity3.html\")\n",
    "\n",
    "fig = px.scatter(x=Xt[:,3], y=Xt[:,4], color=DF['DroughtSensitivity'],hover_name=DF['ScientifName'],width=1000, height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaDroughtSensitivity4.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=DF['FireSensitivity']\n",
    "x=nfeat1\n",
    "skpca2 = sk_pca(n_components=10) \n",
    "# Transform on the scaled features\n",
    "Xt = skpca2.fit_transform(nfeat1)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "fig = px.scatter(x=Xt[:,0], y=Xt[:,1], color=DF['FireSensitivity'],hover_name=DF['ScientifName'], width=1000,height=800)\n",
    "fig.show()\n",
    "fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaFireSensitivity1.html\")\n",
    "fig = px.scatter(x=Xt[:,1], y=Xt[:,2], color=DF['FireSensitivity'],hover_name=DF['ScientifName'], width=1000,height=800)\n",
    "fig.show()\n",
    "fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaFireSensitivity2.html\")\n",
    "fig = px.scatter(x=Xt[:,2], y=Xt[:,3], color=DF['FireSensitivity'],hover_name=DF['ScientifName'], width=1000,height=800)\n",
    "fig.show()\n",
    "fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaFireSensitivity3.html\")\n",
    "\n",
    "fig = px.scatter(x=Xt[:,3], y=Xt[:,4], color=DF['FireSensitivity'],hover_name=DF['ScientifName'],width=1000, height=800)\n",
    "fig.show()\n",
    "fig.write_html(\"D:/地理毕业论文/数据图/噪音2/pcaFireSensitivity4.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=DF['fire or drought Sensitivity']\n",
    "x=nfeat1\n",
    "lda = LDA(n_components=3)\n",
    "Xlda = lda.fit_transform(x,y)\n",
    "Xlda\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2)\n",
    "\n",
    "lda = LDA(n_components=3)\n",
    "lda.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lda.predict(X_test)\n",
    "print(lda.score(X_test,y_test))\n",
    "fig = px.scatter(x=Xlda[:,0], y=Xlda[:,1], color=DF['fire or drought Sensitivity'],hover_name=df['ScientifName'],width=1000, height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/LDADroughtfireSensitivity1.html\")\n",
    "fig = px.scatter(x=Xlda[:,1], y=Xlda[:,2], color=DF['fire or drought Sensitivity'],hover_name=df['ScientifName'],width=1000, height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/数据图/噪音2/LDADroughtfireSensitivity2.html\")\n",
    "fig = px.scatter(x=Xlda[:,0], y=Xlda[:,2], color=DF['fire or drought Sensitivity'],hover_name=df['ScientifName'],width=1000, height=800)\n",
    "#fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=DF['fire or drought Sensitivity']\n",
    "x=nfeat1\n",
    "lda = LDA(n_components=3)\n",
    "Xlda = lda.fit_transform(x,y)\n",
    "Xlda\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2)\n",
    "\n",
    "lda = LDA(n_components=3)\n",
    "lda.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lda.predict(X_test)\n",
    "print(lda.score(X_test,y_test))\n",
    "fig = px.scatter(x=Xlda[:,0], y=Xlda[:,1], color=DF['fire or drought Sensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/newScientifName.html\")\n",
    "fig = px.scatter(x=Xlda[:,1], y=Xlda[:,2], color=DF['fire or drought Sensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/newScientifName2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=DF['fire or drought Sensitivity']\n",
    "x=nfeat2\n",
    "lda = LDA(n_components=3)\n",
    "Xlda = lda.fit_transform(x,y)\n",
    "Xlda\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2)\n",
    "\n",
    "lda = LDA(n_components=3)\n",
    "lda.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lda.predict(X_test)\n",
    "print(lda.score(X_test,y_test))\n",
    "fig = px.scatter(x=Xlda[:,0], y=Xlda[:,1], color=DF['fire or drought Sensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/newScientifName.html\")\n",
    "fig = px.scatter(x=Xlda[:,1], y=Xlda[:,2], color=DF['fire or drought Sensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['ScientifName']\n",
    "x=nfeat1\n",
    "lda = LDA(n_components=9)\n",
    "Xlda = lda.fit_transform(x,y)\n",
    "Xlda\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2)\n",
    "\n",
    "lda = LDA(n_components=9)\n",
    "lda.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lda.predict(X_test)\n",
    "print(lda.score(X_test,y_test))\n",
    "fig = px.scatter(x=Xlda[:,0], y=Xlda[:,1], color=df['ScientifName'],color_discrete_map=dict,width=1000, height=500)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/newScientifName.html\")\n",
    "fig = px.scatter(x=Xlda[:,1], y=Xlda[:,2], color=df['ScientifName'],color_discrete_map=dict,width=1000, height=500)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/newScientifName2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=DF['fire or drought Sensitivity']\n",
    "x=spectral\n",
    "skpca2 = sk_pca(n_components=10) \n",
    "# Transform on the scaled features\n",
    "Xt = skpca2.fit_transform(nfeat1)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "#fig = px.scatter(x=Xt[:,0], y=Xt[:,1], color=DF['fire or drought Sensitivity'], height=800)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/newDroughtSensitivity1.html\")\n",
    "fig = px.scatter(x=Xt[:,3], y=Xt[:,4], color=DF['fire or drought Sensitivity'],width=1000, height=500)\n",
    "#fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/newDroughtSensitivity2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['ScientifName']\n",
    "x=nfeat1\n",
    "skpca2 = sk_pca(n_components=10) \n",
    "# Transform on the scaled features\n",
    "Xt = skpca2.fit_transform(nfeat1)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "fig = px.scatter(x=Xt[:,0], y=Xt[:,1], color=DF['DroughtSensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/latestDroughtSensitivity1.html\")\n",
    "fig = px.scatter(x=Xt[:,1], y=Xt[:,2], color=DF['DroughtSensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "fig.show()\n",
    "fig = px.scatter(x=Xt[:,2], y=Xt[:,3], color=DF['DroughtSensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "fig.show()\n",
    "fig = px.scatter(x=Xt[:,3], y=Xt[:,4], color=DF['DroughtSensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/latestDroughtSensitivity2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['ScientifName']\n",
    "x=nfeat1\n",
    "skpca2 = sk_pca(n_components=10) \n",
    "# Transform on the scaled features\n",
    "Xt = skpca2.fit_transform(nfeat1)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "fig = px.scatter(x=Xt[:,0], y=Xt[:,1], color=DF['FireSensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/latestFireSensitivity1.html\")\n",
    "fig = px.scatter(x=Xt[:,1], y=Xt[:,2], color=DF['FireSensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "fig.show()\n",
    "fig = px.scatter(x=Xt[:,2], y=Xt[:,3], color=DF['FireSensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "fig.show()\n",
    "fig = px.scatter(x=Xt[:,3], y=Xt[:,4], color=DF['FireSensitivity'],hover_name=df['ScientifName'],width=1000, height=500)\n",
    "fig.show()\n",
    "#fig.write_html(\"D:/地理毕业论文/latestFireSensitivity2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes Classifier\n",
    "def naive_bayes_classifier(train_x, train_y):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    model = MultinomialNB(alpha=0.01)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "\n",
    "# KNN Classifier\n",
    "def knn_classifier(train_x, train_y):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Random Forest Classifier\n",
    "def random_forest_classifier(train_x, train_y):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Decision Tree Classifier\n",
    "def decision_tree_classifier(train_x, train_y):\n",
    "    from sklearn import tree\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "\n",
    "# GBDT(Gradient Boosting Decision Tree) Classifier\n",
    "def gradient_boosting_classifier(train_x, train_y):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    model = GradientBoostingClassifier(n_estimators=100)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "\n",
    "# SVM Classifier\n",
    "def svm_classifier(train_x, train_y):\n",
    "    from sklearn.svm import SVC\n",
    "    model = SVC(kernel='rbf', probability=True)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    " # 3 layer neural network classficiation\n",
    "def mlp_classifier(train_x,train_y):\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    model =  MLPClassifier(hidden_layer_sizes=(256,128,32), max_iter=20, alpha=1e-4,\n",
    "                    solver='adam', verbose=10, tol=1e-6, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "    model.fit(train_x,train_y)\n",
    "    return model\n",
    "\n",
    "def CNN(train_x, train_y, exp_max=1350,exp_min=350):\n",
    "    #CNN hyperparameters\n",
    "    BATCH_SIZE=16\n",
    "    n_input = exp_max - exp_min+1\n",
    "    n_classes = 26 \n",
    "    \n",
    "    \n",
    "    # Define network structure\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(K.layers.Conv1D(32, 8,strides=8, padding='same',input_shape=(n_input,1), activation='relu'))\n",
    "    model.add(K.layers.Conv1D(32, 5,strides=5, padding='same', activation='relu'))\n",
    "    model.add(K.layers.Conv1D(16, 3,strides=3, padding='same', activation='relu'))\n",
    "    model.add(K.layers.Flatten())\n",
    "    model.add(K.layers.Dense(1024,activation='relu'))\n",
    "    model.add(K.layers.Dense(n_classes, activation='softmax'))\n",
    "    #Define optimizer        \n",
    "    optimizer =keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    #cannot reshape array of size 72072 into shape (72,1000,1)\n",
    "    train_x = train_x.reshape(train_x.shape[0],n_input,1)\n",
    "    model.fit(train_x,train_y,batch_size=BATCH_SIZE, epochs=4,\n",
    "                         verbose=0)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(K.layers.Conv1D(32, 8,strides=8, padding='same',input_shape=(1001,1), activation='relu'))\n",
    "model.add(K.layers.Conv1D(32, 5,strides=5, padding='same', activation='relu'))\n",
    "model.add(K.layers.Conv1D(16, 3,strides=3, padding='same', activation='relu'))\n",
    "model.add(K.layers.Flatten())\n",
    "model.add(K.layers.Dense(1024,activation='relu'))\n",
    "model.add(K.layers.Dense(26, activation='softmax'))\n",
    "    #Define optimizer        \n",
    "optimizer =keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=set(DF['ScientifName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D= spectral.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#convert from pandas dataframe to numpy array\n",
    "D_arr=np.asmatrix(D)\n",
    "y_th = DF['ScientifName']\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "y_th_onehot = enc.fit_transform(y_th.values .reshape(-1,1))\n",
    "n_fold = 5\n",
    "from sklearn.model_selection import KFold\n",
    "k_fold = KFold(n_splits=n_fold, shuffle=True,random_state=30)\n",
    "test_classifier = ['RF']\n",
    "classifiers = {#'NB':naive_bayes_classifier,   \n",
    "                   'KNN' :knn_classifier,                      \n",
    "                   'RF':random_forest_classifier,  \n",
    "                   'DT':decision_tree_classifier,  \n",
    "                   'SVM':svm_classifier,                    \n",
    "                   #'GBDT':gradient_boosting_classifier,\n",
    "                   #'NN':mlp_classifier,\n",
    "                   'CNN': CNN\n",
    "                   \n",
    "    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "species=[]\n",
    "accuracy_exp = np.empty((n_fold,1))\n",
    "error=np.empty((n_fold,1)) \n",
    "start_time = time.time()   \n",
    "for classifier in classifiers: \n",
    "    print ('******************* %s ********************' % classifier)\n",
    "    for k, (train, test) in enumerate(k_fold.split(D_arr, y_th)):       \n",
    "        #predict experimental prediction accuracy\n",
    "        \n",
    "        pre=[]\n",
    "        \n",
    "        if classifier == 'CNN':\n",
    "            train_y = enc.transform(y_th[train].values.reshape(-1,1))\n",
    "            model = classifiers[classifier](D_arr[train], train_y) \n",
    "            predict_exp = model.predict(np.expand_dims(D_arr[test],2))\n",
    "            predict_exp = enc.inverse_transform(predict_exp)\n",
    "        else:\n",
    "            model = classifiers[classifier](D_arr[train], y_th[train]) \n",
    "            predict_exp = model.predict(D_arr[test])\n",
    "        for p in predict_exp:\n",
    "            pre.append(p)\n",
    "            \n",
    "        accuracy_exp[k] = accuracy_score(y_th[test], predict_exp)\n",
    "        #accuracy=round(accuracy_exp[k], 2)*100\n",
    "        cm=confusion_matrix(y_th[test], predict_exp)\n",
    "\n",
    "\n",
    "\n",
    "        cm=cm/cm.astype(np.float).sum(axis=1,keepdims=True)\n",
    "        plt.figure(figsize=(20,20))\n",
    "        ax= plt.subplot()\n",
    "        #sns.set(rc = {'figure.figsize':(20,10)})\n",
    "        sns.heatmap(cm, annot=True, fmt='.2f', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "        accuracy=np.round(accuracy_exp[k],2)*100\n",
    "        \n",
    "        ax.set_xlabel('Predicted labels\\nAccuracy is : %.2f%%'% (100 * accuracy_exp[k]),fontsize=22)\n",
    "        \n",
    "        ax.set_ylabel('True labels',fontsize=10) \n",
    "        \n",
    "        plt.title('Confusion Matrix\\n classifier is '+classifier,fontsize=22) \n",
    "        ax.xaxis.set_ticklabels(name,rotation=90)\n",
    "        ax.yaxis.set_ticklabels(name,rotation=0)\n",
    "        plt.figure(figsize=(20,20)) \n",
    "        plt.show()\n",
    "        #print ('accuracy_exp: %.2f%%' % (100 * accuracy_exp[k]))\n",
    "\n",
    "\n",
    "    print ('CV  took %fs!' % (time.time() - start_time) )\n",
    "    print('Cross-validation results:')\n",
    "    print('Folds: %i, mean acc: %.3f' % (len(accuracy_exp), np.mean(np.abs(accuracy_exp))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('zijian')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e92a5b951864b817f503e4b4aff3d207d4d7f26758c4cb2ea36d2ac7a108b8d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
